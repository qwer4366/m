// Puter.js AI Service Integration
// This service provides free access to OpenAI, Claude, Gemini and 400+ AI models via Puter.js

import type { PuterChatResponse, PuterStreamResponse } from '@/types/global';

// Fallback for when Puter.js is not available
const createFallbackResponse = (prompt: string, modelId: string): PuterChatResponse => {
  const responses = [
    `Ù…Ø±Ø­Ø¨Ø§Ù‹! Ø£Ù†Ø§ ${modelId}. Ø³Ø¤Ø§Ù„Ùƒ: "${prompt}"\n\nÙ‡Ø°Ù‡ Ø§Ø³ØªØ¬Ø§Ø¨Ø© ØªØ¬Ø±ÙŠØ¨ÙŠØ©. ÙÙŠ Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØŒ Ø³ØªØ­ØµÙ„ Ø¹Ù„Ù‰ Ø¥Ø¬Ø§Ø¨Ø© Ù…ØªÙ‚Ø¯Ù…Ø© Ù…Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ÙØ¹Ù„ÙŠ.`,
    `${modelId} ÙŠØ¬ÙŠØ¨: Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø³Ø¤Ø§Ù„Ùƒ "${prompt}"ØŒ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø§Ù„Ù‚ÙˆÙ„ Ø£Ù† Ù‡Ø°Ø§ Ù…ÙˆØ¶ÙˆØ¹ Ù…Ø«ÙŠØ± Ù„Ù„Ø§Ù‡ØªÙ…Ø§Ù…. ÙÙŠ Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØŒ Ø³ØªØ­ØµÙ„ Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„ Ù…ÙØµÙ„ ÙˆØ¯Ù‚ÙŠÙ‚.`,
    `Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù…Ù† ${modelId}: Ø´ÙƒØ±Ø§Ù‹ Ù„Ø³Ø¤Ø§Ù„Ùƒ "${prompt}". Ù‡Ø°Ù‡ Ù…Ø¹Ø§ÙŠÙ†Ø© Ù„Ù„ÙˆØ¸Ø§Ø¦Ù. Ø¹Ù†Ø¯ ØªÙØ¹ÙŠÙ„ Puter.jsØŒ Ø³ØªØ­ØµÙ„ Ø¹Ù„Ù‰ Ø¥Ø¬Ø§Ø¨Ø§Øª Ø­Ù‚ÙŠÙ‚ÙŠØ© ÙˆÙ…ØªØ·ÙˆØ±Ø©.`
  ];
  
  const randomResponse = responses[Math.floor(Math.random() * responses.length)];
  
  return {
    message: {
      content: [{
        text: randomResponse
      }]
    },
    text: randomResponse,
    success: true
  };
};

export interface AIModel {
  id: string;
  name: string;
  provider: string;
  type: 'text' | 'image' | 'multimodal';
  capabilities: string[];
  icon: string;
  isNew?: boolean;
}

// Available models through Puter.js - Updated with all supported models
export const AVAILABLE_MODELS: AIModel[] = [
  // OpenAI GPT-5 Series
  {
    id: "gpt-5",
    name: "GPT-5",
    provider: "OpenAI",
    type: "text",
    capabilities: ["Ù†Øµ", "ØªØ­Ù„ÙŠÙ„", "Ø¨Ø±Ù…Ø¬Ø©", "Ø¥Ø¨Ø¯Ø§Ø¹"],
    icon: "ğŸš€",
    isNew: true
  },
  {
    id: "gpt-5-nano",
    name: "GPT-5 Nano",
    provider: "OpenAI", 
    type: "text",
    capabilities: ["Ù†Øµ", "Ø³Ø±Ø¹Ø©", "ÙƒÙØ§Ø¡Ø©"],
    icon: "âš¡",
    isNew: true
  },
  {
    id: "gpt-5-mini",
    name: "GPT-5 Mini",
    provider: "OpenAI",
    type: "text", 
    capabilities: ["Ù†Øµ", "Ø³Ø±Ø¹Ø©", "Ø§Ù‚ØªØµØ§Ø¯ÙŠ"],
    icon: "ğŸ”¥",
    isNew: true
  },
  {
    id: "gpt-5-chat-latest",
    name: "GPT-5 Chat Latest",
    provider: "OpenAI",
    type: "text",
    capabilities: ["Ù…Ø­Ø§Ø¯Ø«Ø©", "ØªÙØ§Ø¹Ù„", "Ø­Ø¯ÙŠØ«"],
    icon: "ğŸ’¬",
    isNew: true
  },
  
  // OpenAI GPT-4 Series
  {
    id: "gpt-4.1",
    name: "GPT-4.1",
    provider: "OpenAI",
    type: "text",
    capabilities: ["Ù†Øµ", "ØªØ­Ù„ÙŠÙ„", "Ø¯Ù‚Ø©"],
    icon: "ğŸ“"
  },
  {
    id: "gpt-4.1-mini",
    name: "GPT-4.1 Mini",
    provider: "OpenAI",
    type: "text",
    capabilities: ["Ù†Øµ", "Ø³Ø±Ø¹Ø©", "ÙƒÙØ§Ø¡Ø©"],
    icon: "âš¡"
  },
  {
    id: "gpt-4.1-nano",
    name: "GPT-4.1 Nano",
    provider: "OpenAI",
    type: "text",
    capabilities: ["Ù†Øµ", "Ø³Ø±Ø¹Ø© ÙØ§Ø¦Ù‚Ø©", "Ø®ÙÙŠÙ"],
    icon: "ğŸ”¥"
  },
  {
    id: "gpt-4.5-preview",
    name: "GPT-4.5 Preview",
    provider: "OpenAI",
    type: "text",
    capabilities: ["Ù†Øµ", "Ù…Ø¹Ø§ÙŠÙ†Ø©", "ØªØ·ÙˆÙŠØ±"],
    icon: "ğŸ”¬",
    isNew: true
  },
  {
    id: "gpt-4o",
    name: "GPT-4o",
    provider: "OpenAI",
    type: "multimodal",
    capabilities: ["Ù†Øµ", "ØµÙˆØ±", "ØªØ­Ù„ÙŠÙ„"],
    icon: "ğŸ¯"
  },
  {
    id: "gpt-4o-mini",
    name: "GPT-4o Mini",
    provider: "OpenAI",
    type: "multimodal",
    capabilities: ["Ù†Øµ", "ØµÙˆØ±", "Ø³Ø±Ø¹Ø©"],
    icon: "âš¡"
  },
  
  // OpenAI o-Series (Reasoning Models)
  {
    id: "o1",
    name: "o1",
    provider: "OpenAI",
    type: "text",
    capabilities: ["ØªÙÙƒÙŠØ±", "Ù…Ù†Ø·Ù‚", "Ø±ÙŠØ§Ø¶ÙŠØ§Øª"],
    icon: "ğŸ§ "
  },
  {
    id: "o1-mini",
    name: "o1 Mini",
    provider: "OpenAI",
    type: "text",
    capabilities: ["ØªÙÙƒÙŠØ±", "Ø³Ø±Ø¹Ø©", "Ù…Ù†Ø·Ù‚"],
    icon: "ğŸ§ "
  },
  {
    id: "o1-pro",
    name: "o1 Pro",
    provider: "OpenAI",
    type: "text",
    capabilities: ["ØªÙÙƒÙŠØ± Ù…ØªÙ‚Ø¯Ù…", "ØªØ­Ù„ÙŠÙ„ Ø¹Ù…ÙŠÙ‚"],
    icon: "ğŸ§ "
  },
  {
    id: "o3",
    name: "o3",
    provider: "OpenAI",
    type: "text",
    capabilities: ["ØªÙÙƒÙŠØ±", "Ø¥Ø¨Ø¯Ø§Ø¹", "Ø­Ù„ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„"],
    icon: "ğŸ§ ",
    isNew: true
  },
  {
    id: "o3-mini",
    name: "o3 Mini",
    provider: "OpenAI",
    type: "text",
    capabilities: ["ØªÙÙƒÙŠØ±", "Ø³Ø±Ø¹Ø©", "ÙƒÙØ§Ø¡Ø©"],
    icon: "ğŸ§ ",
    isNew: true
  },
  {
    id: "o4-mini",
    name: "o4 Mini",
    provider: "OpenAI",
    type: "text",
    capabilities: ["ØªÙÙƒÙŠØ± Ù…ØªØ·ÙˆØ±", "Ø³Ø±Ø¹Ø©"],
    icon: "ğŸ§ ",
    isNew: true
  },
  
  // Anthropic Claude Models
  {
    id: "claude-sonnet-4",
    name: "Claude Sonnet 4",
    provider: "Anthropic",
    type: "text",
    capabilities: ["Ù†Øµ", "ØªØ­Ù„ÙŠÙ„", "Ø¥Ø¨Ø¯Ø§Ø¹", "Ø£Ù…Ø§Ù†"],
    icon: "ğŸ­",
    isNew: true
  },
  {
    id: "claude-opus-4",
    name: "Claude Opus 4",
    provider: "Anthropic",
    type: "text",
    capabilities: ["ØªØ­Ù„ÙŠÙ„ Ø¹Ù…ÙŠÙ‚", "Ø¥Ø¨Ø¯Ø§Ø¹", "ØªÙÙƒÙŠØ±"],
    icon: "ğŸ¨",
    isNew: true
  },
  {
    id: "claude-3-7-sonnet",
    name: "Claude 3.7 Sonnet",
    provider: "Anthropic",
    type: "text",
    capabilities: ["Ù†Øµ", "ØªØ­Ù„ÙŠÙ„", "ØªÙˆØ§Ø²Ù†"],
    icon: "ğŸ­"
  },
  
  // Google Gemini Models
  {
    id: "google/gemini-2.5-flash",
    name: "Gemini 2.5 Flash",
    provider: "Google",
    type: "multimodal",
    capabilities: ["Ù†Øµ", "ØµÙˆØ±", "Ø³Ø±Ø¹Ø©", "ØªØ­Ù„ÙŠÙ„"],
    icon: "ğŸ’",
    isNew: true
  },
  {
    id: "google/gemini-pro",
    name: "Gemini Pro",
    provider: "Google",
    type: "multimodal",
    capabilities: ["Ù†Øµ", "ØµÙˆØ±", "ØªØ­Ù„ÙŠÙ„ Ù…ØªÙ‚Ø¯Ù…"],
    icon: "ğŸ’"
  },
  
  // Meta Llama Models
  {
    id: "meta/llama-3.3-70b",
    name: "Llama 3.3 70B",
    provider: "Meta",
    type: "text",
    capabilities: ["Ù†Øµ", "Ù…ÙØªÙˆØ­ Ø§Ù„Ù…ØµØ¯Ø±", "Ù‚ÙˆÙŠ"],
    icon: "ğŸ¦™",
    isNew: true
  },
  {
    id: "meta/llama-3.2-90b",
    name: "Llama 3.2 90B",
    provider: "Meta",
    type: "multimodal",
    capabilities: ["Ù†Øµ", "ØµÙˆØ±", "Ù…ÙØªÙˆØ­ Ø§Ù„Ù…ØµØ¯Ø±"],
    icon: "ğŸ¦™"
  },
  
  // Image Generation Models
  {
    id: "dall-e-3",
    name: "DALL-E 3",
    provider: "OpenAI",
    type: "image",
    capabilities: ["ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±", "Ø¥Ø¨Ø¯Ø§Ø¹ Ø¨ØµØ±ÙŠ"],
    icon: "ğŸ¨"
  },
  {
    id: "midjourney",
    name: "Midjourney",
    provider: "Midjourney",
    type: "image",
    capabilities: ["ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±", "ÙÙ†ÙŠ", "Ø¥Ø¨Ø¯Ø§Ø¹ÙŠ"],
    icon: "ğŸ–¼ï¸"
  },
  {
    id: "stable-diffusion-xl",
    name: "Stable Diffusion XL",
    provider: "Stability AI",
    type: "image",
    capabilities: ["ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±", "Ù…ÙØªÙˆØ­ Ø§Ù„Ù…ØµØ¯Ø±"],
    icon: "ğŸ¨"
  }
];

export class PuterAIService {
  private static instance: PuterAIService;
  private isInitialized = false;
  private initPromise: Promise<void> | null = null;
  
  public static getInstance(): PuterAIService {
    if (!PuterAIService.instance) {
      PuterAIService.instance = new PuterAIService();
    }
    return PuterAIService.instance;
  }

  private constructor() {
    this.initPromise = this.initialize();
  }

  private async initialize(): Promise<void> {
    if (this.isInitialized) return;

    // Wait for DOM to be ready
    if (typeof window === 'undefined') return;

    // Check if Puter.js is already loaded
    if (window.puter?.ai) {
      this.isInitialized = true;
      return;
    }

    // Wait for Puter.js to load (with timeout)
    const timeout = 10000; // 10 seconds
    const startTime = Date.now();

    while (!window.puter?.ai && (Date.now() - startTime) < timeout) {
      await new Promise(resolve => setTimeout(resolve, 100));
    }

    if (window.puter?.ai) {
      this.isInitialized = true;
      console.log('Puter.js initialized successfully');
    } else {
      console.warn('Puter.js failed to load within timeout period');
    }
  }

  private async ensureInitialized(): Promise<void> {
    if (this.initPromise) {
      await this.initPromise;
    }
  }

  /**
   * Generate text using specified model
   */
  async generateText(prompt: string, modelId: string, options: {
    temperature?: number;
    max_tokens?: number;
    stream?: boolean;
    tools?: any[];
  } = {}): Promise<PuterChatResponse> {
    await this.ensureInitialized();

    if (!window.puter?.ai) {
      console.warn('Puter.js not available, using fallback response');
      return createFallbackResponse(prompt, modelId);
    }

    try {
      // Use the correct Puter.js API format
      const requestOptions: any = {
        model: modelId
      };
      
      // Add optional parameters if provided
      if (options.temperature !== undefined) {
        requestOptions.temperature = options.temperature;
      }
      if (options.max_tokens !== undefined) {
        requestOptions.max_tokens = options.max_tokens;
      }
      if (options.tools !== undefined) {
        requestOptions.tools = options.tools;
      }
      if (options.stream !== undefined) {
        requestOptions.stream = options.stream;
      }

      const response = await window.puter.ai.chat(prompt, requestOptions);
      
      // Handle different response formats
      if (typeof response === 'string') {
        return {
          message: {
            content: [{ text: response }]
          },
          text: response,
          success: true
        };
      }
      
      // Handle Claude-style responses
      if (response.message?.content?.[0]?.text) {
        return {
          message: response.message,
          text: response.message.content[0].text,
          success: true
        };
      }
      
      // Handle other response formats
      return {
        message: {
          content: [{ text: response.toString() }]
        },
        text: response.toString(),
        success: true
      };
      
    } catch (error) {
      console.error('Error generating text:', error);
      // Return fallback instead of throwing
      return createFallbackResponse(prompt, modelId);
    }
  }

  /**
   * Generate text with streaming support
   */
  async generateTextStream(prompt: string, modelId: string, options: {
    temperature?: number;
    max_tokens?: number;
  } = {}): Promise<AsyncIterable<any>> {
    if (!window.puter?.ai) {
      // Return a simple async iterable for fallback
      const fallbackResponse = createFallbackResponse(prompt, modelId);
      return {
        async *[Symbol.asyncIterator]() {
          const text = fallbackResponse.text;
          const words = text.split(' ');
          for (const word of words) {
            yield { text: word + ' ' };
            await new Promise(resolve => setTimeout(resolve, 50));
          }
        }
      };
    }

    try {
      const response = await window.puter.ai.chat(prompt, {
        model: modelId,
        stream: true,
        ...options
      });
      
      return response;
    } catch (error) {
      console.error('Error generating text stream:', error);
      // Return fallback stream
      const fallbackResponse = createFallbackResponse(prompt, modelId);
      return {
        async *[Symbol.asyncIterator]() {
          yield { text: fallbackResponse.text };
        }
      };
    }
  }

  /**
   * Generate image using DALL-E 3 or other image models
   */
  async generateImage(prompt: string, options: any = {}): Promise<HTMLImageElement> {
    await this.ensureInitialized();
    
    if (!window.puter?.ai) {
      // Create a placeholder image element
      const img = document.createElement('img');
      img.src = 'data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNTEyIiBoZWlnaHQ9IjUxMiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj48ZGVmcz48bGluZWFyR3JhZGllbnQgaWQ9ImciIHgxPSIwJSIgeTE9IjAlIiB4Mj0iMTAwJSIgeTI9IjEwMCUiPjxzdG9wIG9mZnNldD0iMCUiIHN0b3AtY29sb3I9IiM2MzY2ZjEiLz48c3RvcCBvZmZzZXQ9IjEwMCUiIHN0b3AtY29sb3I9IiM4YjVjZjYiLz48L2xpbmVhckdyYWRpZW50PjwvZGVmcz48cmVjdCB3aWR0aD0iMTAwJSIgaGVpZ2h0PSIxMDAlIiBmaWxsPSJ1cmwoI2cpIi8+PHRleHQgeD0iNTAlIiB5PSI0NSUiIGZvbnQtZmFtaWx5PSJBcmlhbCwgc2Fucy1zZXJpZiIgZm9udC1zaXplPSIyNCIgZmlsbD0id2hpdGUiIHRleHQtYW5jaG9yPSJtaWRkbGUiIGR5PSIuM2VtIj7wn46oINmF2YjZhNivINin2YTYtdmI2LE8L3RleHQ+PHRleHQgeD0iNTAlIiB5PSI2MCUiIGZvbnQtZmFtaWx5PSJBcmlhbCwgc2Fucy1zZXJpZiIgZm9udC1zaXplPSIxNiIgZmlsbD0icmdiYSgyNTUsMjU1LDI1NSwwLjgpIiB0ZXh0LWFuY2hvcj0ibWlkZGxlIiBkeT0iLjNlbSI+2YXYudin2YrZhtipIC0g2LPZitiq2YUg2KXZhtiq2KfYrCDYp9mE2LXZiNix2Kkg2YHZiSDYp9mE2YjYttmFINin2YTYrdmC2YrZgtmKPC90ZXh0PjwvdGV4dD48L3N2Zz4=';
      img.alt = 'Ù…Ø¹Ø§ÙŠÙ†Ø© - Ø³ÙŠØªÙ… Ø¥Ù†ØªØ§Ø¬ Ø§Ù„ØµÙˆØ±Ø© ÙÙŠ Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ';
      img.style.width = '512px';
      img.style.height = '512px';
      img.style.borderRadius = '8px';
      return img;
    }

    try {
      // Use Puter.js txt2img function
      const imageElement = await window.puter.ai.txt2img(prompt, options);
      
      // Ensure the image has proper styling
      if (imageElement) {
        imageElement.style.maxWidth = '100%';
        imageElement.style.height = 'auto';
        imageElement.style.borderRadius = '8px';
        imageElement.alt = `Generated image: ${prompt}`;
      }
      
      return imageElement;
    } catch (error) {
      console.error('Error generating image:', error);
      // Return error placeholder
      const img = document.createElement('img');
      img.src = 'data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNTEyIiBoZWlnaHQ9IjUxMiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj48cmVjdCB3aWR0aD0iMTAwJSIgaGVpZ2h0PSIxMDAlIiBmaWxsPSIjZjNmNGY2Ii8+PHRleHQgeD0iNTAlIiB5PSI0NSUiIGZvbnQtZmFtaWx5PSJBcmlhbCwgc2Fucy1zZXJpZiIgZm9udC1zaXplPSIyNCIgZmlsbD0iI2VmNDQ0NCIgdGV4dC1hbmNob3I9Im1pZGRsZSIgZHk9Ii4zZW0iPuKaoCDYrtio2KMg2YHZiiDYp9mE2KXZhtiq2KfYrDwvdGV4dD48dGV4dCB4PSI1MCUiIHk9IjYwJSIgZm9udC1mYW1pbHk9IkFyaWFsLCBzYW5zLXNlcmlmIiBmb250LXNpemU9IjE2IiBmaWxsPSIjNmI3Mjg0IiB0ZXh0LWFuY2hvcj0ibWlkZGxlIiBkeT0iLjNlbSI+2YrYsdis2Ykg2KfZhNmF2K3Yp9mI2YTYqSDZhdix2Kkg2KPYrtix2YnYjCDYo9mIINiq2KPZg9ivINmF2YYg2KfZhNin2KrYtdin2YQg2KjYp9mE2KXZhtiq2LHZhtiqPC90ZXh0Pjwvc3ZnPg==';
      img.alt = 'Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†ØªØ§Ø¬ Ø§Ù„ØµÙˆØ±Ø©';
      img.style.width = '512px';
      img.style.height = '512px';
      img.style.borderRadius = '8px';
      return img;
    }
  }

  /**
   * Analyze image with vision models
   */
  async analyzeImage(prompt: string, imageUrl: string, modelId: string = "gpt-5-nano"): Promise<any> {
    if (!window.puter?.ai) {
      return createFallbackResponse(`ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©: ${prompt}`, modelId);
    }

    try {
      const response = await window.puter.ai.chat(prompt, imageUrl, {
        model: modelId
      });
      
      return response;
    } catch (error) {
      console.error('Error analyzing image:', error);
      return createFallbackResponse(`ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©: ${prompt}`, modelId);
    }
  }

  /**
   * Get available models
   */
  getAvailableModels(): AIModel[] {
    return AVAILABLE_MODELS;
  }

  /**
   * Get model by ID
   */
  getModelById(id: string): AIModel | undefined {
    return AVAILABLE_MODELS.find(model => model.id === id);
  }

  /**
   * Get models by provider
   */
  getModelsByProvider(provider: string): AIModel[] {
    return AVAILABLE_MODELS.filter(model => model.provider === provider);
  }

  /**
   * Get models by type
   */
  getModelsByType(type: 'text' | 'image' | 'multimodal'): AIModel[] {
    return AVAILABLE_MODELS.filter(model => model.type === type);
  }

  /**
   * Function calling example
   */
  async callFunction(prompt: string, tools: any[], modelId: string = "gpt-5"): Promise<any> {
    if (!window.puter?.ai) {
      return createFallbackResponse(`Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø¯Ø§Ù„Ø©: ${prompt}`, modelId);
    }

    try {
      const response = await window.puter.ai.chat(prompt, { 
        model: modelId,
        tools 
      });
      
      return response;
    } catch (error) {
      console.error('Error calling function:', error);
      return createFallbackResponse(`Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø¯Ø§Ù„Ø©: ${prompt}`, modelId);
    }
  }
}

// Export singleton instance
export const puterAI = PuterAIService.getInstance();